# 阿里云 API 接口文档汇总

本文档整理了 Echobot 项目中需要使用的三个阿里云 API 服务接口，用于实现儿童故事 mp4 视频的声音克隆与数字人头像生成功能。

---

## 业务流程概述

### 最终目标
将儿童故事 mp4 视频中的播音员声音替换为父母克隆的声音，并在视频右上角添加父母的数字人头像（对口型），生成新的故事视频。

### 完整流程

```
原始mp4视频
    ↓
[步骤1] 智能媒体服务IMS - 视频分离
    ├─ 提取音频
    ├─ 提取字幕（SRT带时间线）
    └─ 提取原视频（静音处理）
    ↓
[步骤2] CosyVoice 声音克隆
    ├─ 上传父母音频样本（10-20秒）
    ├─ 创建专属音色
    └─ 基于字幕生成父母声音的完整音频
    ↓
[步骤3] 悦动人像 EMO - 数字人生成
    ├─ 上传父母照片
    ├─ 图像检测（emo-detect-v1）
    └─ 生成口型匹配的数字人视频
    ↓
[步骤4] 智能媒体服务IMS - 视频合成
    ├─ 原视频（静音）
    ├─ 父母声音音频
    ├─ 数字人头像视频（右上角）
    └─ 新的BGM（可选）
    ↓
最终成片：带父母声音和数字人的新故事mp4
```

---

## 一、智能媒体服务 IMS (Intelligent Media Services)

### 1.1 服务概述

智能媒体服务 IMS 提供媒体处理能力，包括视频音频分离、字幕提取、视频合成等功能。

**适用地域**: 华东2（上海）、华北2（北京）、华南1（深圳）、华东1（杭州）等

**官方文档**: https://help.aliyun.com/zh/ims/

### 1.2 API 接口

#### 1.2.1 提交剪辑合成作业 (SubmitMediaProducingJob)

**接口地址**: `POST https://ice.cn-{region}.aliyuncs.com/`

**功能说明**:
- 提交媒体剪辑合成任务
- 支持视频音频分离、合成、剪辑等操作
- 异步执行任务，返回 JobId 用于查询结果

**关键限制**:
- QPS限制: 30 次/秒
- 视频轨/图片轨/字幕轨: 每种最多 100 个
- 素材文件总大小: ≤ 1 TB
- 成片分辨率: 宽高 128px-4096px，短边 ≤ 2160px

**核心参数**:

| 参数 | 类型 | 必填 | 说明 |
|------|------|------|------|
| Timeline | string | 是 | 云剪辑时间线配置，定义素材编排和特效 |
| OutputMediaConfig | object | 是 | 输出媒体配置（格式、分辨率、码率等） |
| MediaProduceConfig | object | 否 | 任务配置（转码模式、优先级等） |

**Timeline 配置示例**（视频合成）:
```json
{
  "VideoTracks": [{
    "VideoTrackClips": [{
      "MediaURL": "https://your-bucket.oss-cn-beijing.aliyuncs.com/original-video-muted.mp4",
      "Type": "Video",
      "X": 0,
      "Y": 0,
      "Width": 1920,
      "Height": 1080
    }]
  }],
  "AudioTracks": [{
    "AudioTrackClips": [{
      "MediaURL": "https://your-bucket.oss-cn-beijing.aliyuncs.com/parent-voice.mp3",
      "Type": "Audio"
    }]
  }],
  "EffectTracks": [{
    "EffectTrackClips": [{
      "Type": "Video",
      "MediaURL": "https://your-bucket.oss-cn-beijing.aliyuncs.com/digital-avatar.mp4",
      "X": 1520,
      "Y": 100,
      "Width": 300,
      "Height": 300
    }]
  }]
}
```

**字幕提取方式**:
- 通过 Timeline 配置指定字幕提取任务
- 支持 OCR识别、ASR识别、OCR/ASR混合识别
- 输出格式: SRT (带时间轴)

**Python 调用示例**:
```python
from aliyunsdkcore.client import AcsClient
from aliyunsdkice.request.v20201109 import SubmitMediaProducingJobRequest
import json

# 初始化客户端
client = AcsClient('<your-access-key-id>', '<your-access-key-secret>', 'cn-beijing')

# 构建请求
request = SubmitMediaProducingJobRequest.SubmitMediaProducingJobRequest()

# 设置Timeline
timeline_config = {
    "VideoTracks": [...],
    "AudioTracks": [...],
    "EffectTracks": [...]
}
request.set_Timeline(json.dumps(timeline_config))

# 设置输出配置
output_config = {
    "MediaURL": "https://your-bucket.oss-cn-beijing.aliyuncs.com/output.mp4",
    "Width": 1920,
    "Height": 1080,
    "Bitrate": "3000"
}
request.set_OutputMediaConfig(json.dumps(output_config))

# 发送请求
response = client.do_action_with_exception(request)
result = json.loads(response)
job_id = result['JobId']
```

#### 1.2.2 查询剪辑合成作业 (GetMediaProducingJob)

**功能**: 查询任务状态和结果

**参数**: JobId (从提交任务返回)

**状态值**:
- `Success`: 任务成功
- `Failed`: 任务失败
- `Processing`: 处理中
- `Init`: 初始化

---

## 二、CosyVoice 声音克隆服务

### 2.1 服务概述

CosyVoice 是基于生成式语音大模型的声音复刻服务，使用 10-20 秒音频样本即可生成高度相似的定制声音。

**适用地域**: 仅限"中国大陆（北京）"

**官方文档**: https://help.aliyun.com/zh/model-studio/cosyvoice-clone-api

### 2.2 计费说明

| 项目 | 说明 |
|------|------|
| 声音复刻 | 创建/查询/更新/删除音色免费 |
| 语音合成 | 按文本字符数计费（cosyvoice-v3-plus: 2元/万字符） |
| 免费额度 | 新用户有 1 万字符免费额度（90天有效期） |

### 2.3 工作流程

```
1. 创建音色 (create_voice)
   ↓ 返回 voice_id
2. 查询音色状态 (query_voice)
   ↓ 等待状态变为 "OK"
3. 使用音色进行语音合成 (SpeechSynthesizer.call)
   ↓ 返回音频二进制数据
```

### 2.4 API 接口

#### 2.4.1 创建音色

**Python SDK 调用**:
```python
from dashscope.audio.tts_v2 import VoiceEnrollmentService
import os

# 配置API Key
dashscope.api_key = os.getenv("DASHSCOPE_API_KEY")

service = VoiceEnrollmentService()

# 创建音色
voice_id = service.create_voice(
    target_model='cosyvoice-v3-plus',  # 语音合成模型
    prefix='myvoice',                   # 音色名称前缀（仅数字小写字母，<10字符）
    url='https://your-audio-url.wav',   # 音频样本URL
    language_hints=['zh']               # 目标语言（可选）
)

print(f"Voice ID: {voice_id}")
print(f"Request ID: {service.get_last_request_id()}")
```

**RESTful API 调用**:
```bash
curl -X POST https://dashscope.aliyuncs.com/api/v1/services/audio/tts/customization \
  -H "Authorization: Bearer $DASHSCOPE_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "voice-enrollment",
    "input": {
      "action": "create_voice",
      "target_model": "cosyvoice-v3-plus",
      "prefix": "myvoice",
      "url": "https://your-audio-url.wav"
    }
  }'
```

**音频要求**:
- 格式: WAV (16bit), MP3, M4A
- 时长: 推荐 10-20 秒，最长 60 秒
- 文件大小: ≤ 10 MB
- 采样率: ≥ 16 kHz
- 内容: 至少 5 秒连续清晰朗读，无背景音乐/噪音

**关键参数**:
- `target_model`: 驱动音色的语音合成模型（必须与后续合成时使用的模型一致！）
  - 推荐: `cosyvoice-v3-plus` (最佳效果)
  - 平衡: `cosyvoice-v3-flash` (性价比高)
  - 兼容: `cosyvoice-v2`, `cosyvoice-v1`
- `prefix`: 音色标识，生成的音色ID格式为 `{model}-{prefix}-{唯一标识}`

#### 2.4.2 查询音色状态

```python
# 轮询查询音色状态
import time

max_attempts = 30
poll_interval = 10  # 秒

for attempt in range(max_attempts):
    voice_info = service.query_voice(voice_id=voice_id)
    status = voice_info.get("status")

    if status == "OK":
        print("音色准备就绪")
        break
    elif status == "UNDEPLOYED":
        print("音色处理失败")
        break

    time.sleep(poll_interval)
```

**状态值**:
- `OK`: 音色可用
- `DEPLOYING`: 处理中
- `UNDEPLOYED`: 失败

#### 2.4.3 语音合成

**Python SDK 调用**:
```python
from dashscope.audio.tts_v2 import SpeechSynthesizer

# 创建合成器
synthesizer = SpeechSynthesizer(
    model='cosyvoice-v3-plus',  # 必须与创建音色时的target_model一致！
    voice=voice_id               # 使用复刻的音色
)

# 合成语音
text = "恭喜，已成功复刻并合成了属于自己的声音！"
audio_data = synthesizer.call(text)

# 保存音频
with open("output.mp3", "wb") as f:
    f.write(audio_data)
```

**支持 SSML 标记**（仅 v3 模型）:
```python
ssml_text = '''
<speak>
    <prosody rate="slow">这是慢速朗读</prosody>
    <break time="500ms"/>
    <prosody rate="fast">这是快速朗读</prosody>
</speak>
'''
audio_data = synthesizer.call(ssml_text)
```

### 2.5 完整端到端示例

```python
import os
import time
import dashscope
from dashscope.audio.tts_v2 import VoiceEnrollmentService, SpeechSynthesizer

# 1. 环境准备
dashscope.api_key = os.getenv("DASHSCOPE_API_KEY")

# 2. 定义参数
TARGET_MODEL = "cosyvoice-v3-plus"
VOICE_PREFIX = "parentvoice"
AUDIO_URL = "https://your-bucket.oss-cn-beijing.aliyuncs.com/parent-sample.wav"

# 3. 创建音色
service = VoiceEnrollmentService()
voice_id = service.create_voice(
    target_model=TARGET_MODEL,
    prefix=VOICE_PREFIX,
    url=AUDIO_URL
)
print(f"Voice ID: {voice_id}")

# 4. 轮询查询状态
for attempt in range(30):
    voice_info = service.query_voice(voice_id=voice_id)
    status = voice_info.get("status")
    print(f"Attempt {attempt + 1}: Status = {status}")

    if status == "OK":
        break
    time.sleep(10)

# 5. 使用音色合成（根据字幕文本）
synthesizer = SpeechSynthesizer(model=TARGET_MODEL, voice=voice_id)

# 假设从字幕文件读取文本
subtitle_text = "很久很久以前，在一个遥远的森林里，住着一只可爱的小兔子..."
audio_data = synthesizer.call(subtitle_text)

# 6. 保存音频
output_file = "parent_voice_story.mp3"
with open(output_file, "wb") as f:
    f.write(audio_data)
print(f"Audio saved: {output_file}")
```

---

## 三、悦动人像 EMO (数字人视频生成)

### 3.1 服务概述

悦动人像 EMO 可基于人物肖像图片和人声音频生成高质量的人物肖像动态视频（头像/半身像）。

**适用地域**: 仅限"中国大陆（北京）"

**官方文档**: https://help.aliyun.com/zh/model-studio/emo-quick-start

### 3.2 两个核心模型

| 模型 | 功能 | 说明 |
|------|------|------|
| emo-detect-v1 | 图像检测 | 检测图片是否符合要求，返回人脸区域和动态区域坐标 |
| emo-v1 | 视频生成 | 基于图片+音频生成口型匹配的数字人视频 |

### 3.3 计费说明

| 项目 | 单价 | 免费额度 |
|------|------|----------|
| emo-detect-v1 | 0.004元/张 | 200张 |
| emo-v1 (1:1画幅) | 0.08元/秒 | 1800秒 |
| emo-v1 (3:4画幅) | 0.16元/秒 | 1800秒 |

**并发限制**:
- 图像检测: 无限制（同步接口）
- 视频生成: 同时只能有 1 个任务在处理，其他排队

### 3.4 API 接口

#### 3.4.1 图像检测 API (emo-detect-v1)

**功能**: 检测人物肖像图片是否符合 EMO 视频生成的要求，返回人脸区域和动态区域坐标。

**接口地址**: `POST https://dashscope.aliyuncs.com/api/v1/services/aigc/image2video/face-detect`

**请求示例**:
```bash
curl --location 'https://dashscope.aliyuncs.com/api/v1/services/aigc/image2video/face-detect' \
  --header "Authorization: Bearer $DASHSCOPE_API_KEY" \
  --header 'Content-Type: application/json' \
  --data '{
    "model": "emo-detect-v1",
    "input": {
      "image_url": "https://your-bucket.oss-cn-beijing.aliyuncs.com/parent-photo.jpg"
    },
    "parameters": {
      "ratio": "1:1"
    }
  }'
```

**参数说明**:

| 参数 | 类型 | 必填 | 说明 |
|------|------|------|------|
| model | string | 是 | 固定为 `emo-detect-v1` |
| input.image_url | string | 是 | 图片URL（公网可访问） |
| parameters.ratio | string | 是 | 画幅比例：`1:1`（头像）或 `3:4`（半身像） |

**图片要求**:
- 格式: jpg, jpeg, png, bmp, webp
- 分辨率: 最小边长 ≥ 400px，最大边长 ≤ 7000px
- 仅支持 HTTP/HTTPS 链接

**响应示例**（成功）:
```json
{
  "output": {
    "check_pass": true,
    "face_bbox": [302, 286, 610, 593],
    "ext_bbox": [71, 9, 840, 778]
  },
  "usage": {
    "image_count": 1
  },
  "request_id": "7574ee8f-38a3-4b1e-9280-xxxxx"
}
```

**响应字段**:
- `check_pass`: 检测是否通过（true/false）
- `face_bbox`: 人脸区域坐标 [x1, y1, x2, y2]
- `ext_bbox`: 动态区域坐标 [x1, y1, x2, y2]（用于视频生成）

#### 3.4.2 视频生成 API (emo-v1)

**功能**: 基于人物肖像图片和人声音频生成口型匹配的数字人视频。

**接口地址**: `POST https://dashscope.aliyuncs.com/api/v1/services/aigc/image2video/video-synthesis`

**步骤1: 创建任务**

```bash
curl --location 'https://dashscope.aliyuncs.com/api/v1/services/aigc/image2video/video-synthesis' \
  --header 'X-DashScope-Async: enable' \
  --header "Authorization: Bearer $DASHSCOPE_API_KEY" \
  --header 'Content-Type: application/json' \
  --data '{
    "model": "emo-v1",
    "input": {
      "image_url": "https://your-bucket.oss-cn-beijing.aliyuncs.com/parent-photo.jpg",
      "audio_url": "https://your-bucket.oss-cn-beijing.aliyuncs.com/parent-voice.mp3",
      "face_bbox": [302, 286, 610, 593],
      "ext_bbox": [71, 9, 840, 778]
    },
    "parameters": {
      "style_level": "normal"
    }
  }'
```

**参数说明**:

| 参数 | 类型 | 必填 | 说明 |
|------|------|------|------|
| model | string | 是 | 固定为 `emo-v1` |
| input.image_url | string | 是 | 人物肖像图片URL |
| input.audio_url | string | 是 | 人声音频URL |
| input.face_bbox | array | 是 | 人脸区域坐标（从图像检测API获取） |
| input.ext_bbox | array | 是 | 动态区域坐标（从图像检测API获取） |
| parameters.style_level | string | 否 | 动作风格：`calm`/`normal`/`active` |

**音频要求**:
- 格式: wav, mp3
- 文件大小: ≤ 15 MB
- 时长: ≤ 60 秒
- 内容: 清晰人声，去除背景音乐/噪音

**响应示例**（任务创建成功）:
```json
{
  "output": {
    "task_id": "8f1e2d3c-4b5a-6c7d-8e9f-0a1b2c3d4e5f"
  },
  "request_id": "a1b2c3d4-e5f6-7890-abcd-ef1234567890"
}
```

**步骤2: 查询任务结果**

```bash
curl --location 'https://dashscope.aliyuncs.com/api/v1/tasks/{task_id}' \
  --header "Authorization: Bearer $DASHSCOPE_API_KEY"
```

**响应示例**（任务成功）:
```json
{
  "output": {
    "task_id": "8f1e2d3c-4b5a-6c7d-8e9f-0a1b2c3d4e5f",
    "task_status": "SUCCEEDED",
    "video_url": "https://dashscope-result.oss-cn-beijing.aliyuncs.com/xxx/output.mp4",
    "submit_time": "2025-12-26T10:00:00Z",
    "end_time": "2025-12-26T10:05:00Z"
  },
  "usage": {
    "duration": 15.5
  },
  "request_id": "..."
}
```

**任务状态**:
- `PENDING`: 排队中
- `RUNNING`: 处理中
- `SUCCEEDED`: 成功
- `FAILED`: 失败

### 3.5 Python 完整调用示例

```python
import requests
import os
import time

api_key = os.getenv("DASHSCOPE_API_KEY")
base_url = "https://dashscope.aliyuncs.com/api/v1"

# 步骤1: 图像检测
def detect_face(image_url):
    url = f"{base_url}/services/aigc/image2video/face-detect"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": "emo-detect-v1",
        "input": {
            "image_url": image_url
        },
        "parameters": {
            "ratio": "1:1"
        }
    }

    response = requests.post(url, headers=headers, json=payload)
    result = response.json()

    if result['output']['check_pass']:
        return result['output']['face_bbox'], result['output']['ext_bbox']
    else:
        raise Exception("图像检测未通过")

# 步骤2: 创建视频生成任务
def create_video_task(image_url, audio_url, face_bbox, ext_bbox):
    url = f"{base_url}/services/aigc/image2video/video-synthesis"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
        "X-DashScope-Async": "enable"
    }
    payload = {
        "model": "emo-v1",
        "input": {
            "image_url": image_url,
            "audio_url": audio_url,
            "face_bbox": face_bbox,
            "ext_bbox": ext_bbox
        },
        "parameters": {
            "style_level": "normal"
        }
    }

    response = requests.post(url, headers=headers, json=payload)
    result = response.json()
    return result['output']['task_id']

# 步骤3: 查询任务结果
def query_task(task_id):
    url = f"{base_url}/tasks/{task_id}"
    headers = {
        "Authorization": f"Bearer {api_key}"
    }

    response = requests.get(url, headers=headers)
    return response.json()

# 完整流程
if __name__ == "__main__":
    image_url = "https://your-bucket.oss-cn-beijing.aliyuncs.com/parent-photo.jpg"
    audio_url = "https://your-bucket.oss-cn-beijing.aliyuncs.com/parent-voice.mp3"

    # 1. 图像检测
    print("正在检测图像...")
    face_bbox, ext_bbox = detect_face(image_url)
    print(f"检测通过: face_bbox={face_bbox}, ext_bbox={ext_bbox}")

    # 2. 创建视频任务
    print("正在创建视频生成任务...")
    task_id = create_video_task(image_url, audio_url, face_bbox, ext_bbox)
    print(f"任务创建成功: task_id={task_id}")

    # 3. 轮询查询结果
    print("正在等待视频生成...")
    while True:
        result = query_task(task_id)
        status = result['output']['task_status']
        print(f"任务状态: {status}")

        if status == "SUCCEEDED":
            video_url = result['output']['video_url']
            print(f"视频生成成功: {video_url}")
            break
        elif status == "FAILED":
            print("视频生成失败")
            break

        time.sleep(10)
```

---

## 四、项目集成要点

### 4.1 环境变量配置

```bash
# 阿里云API密钥（IMS服务）
export ALIYUN_ACCESS_KEY_ID="your-access-key-id"
export ALIYUN_ACCESS_KEY_SECRET="your-access-key-secret"

# 大模型服务平台百炼API密钥（CosyVoice + EMO）
export DASHSCOPE_API_KEY="sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"

# OSS配置
export OSS_BUCKET="your-bucket-name"
export OSS_REGION="cn-beijing"
```

### 4.2 OSS 文件上传

所有服务都要求素材文件通过公网 URL 访问，推荐使用阿里云 OSS：

```python
import oss2

# 初始化OSS客户端
auth = oss2.Auth('your-access-key-id', 'your-access-key-secret')
bucket = oss2.Bucket(auth, 'https://oss-cn-beijing.aliyuncs.com', 'your-bucket-name')

# 上传文件
def upload_to_oss(local_file, object_name):
    bucket.put_object_from_file(object_name, local_file)

    # 生成公网URL
    url = f"https://{bucket.bucket_name}.oss-cn-beijing.aliyuncs.com/{object_name}"
    return url

# 示例
parent_audio_url = upload_to_oss("parent_sample.wav", "audio/parent_sample.wav")
parent_photo_url = upload_to_oss("parent_photo.jpg", "images/parent_photo.jpg")
```

### 4.3 注意事项

1. **地域一致性**
   - CosyVoice 和 EMO: 仅支持"中国大陆（北京）"
   - IMS: 多地域支持，但 OSS Bucket 必须与 IMS 地域一致

2. **模型一致性**
   - CosyVoice 创建音色时的 `target_model` 必须与后续语音合成时使用的模型完全一致

3. **API 调用顺序**
   - EMO 必须先调用图像检测 API，获取 face_bbox 和 ext_bbox
   - CosyVoice 必须先创建音色并等待状态为 OK，才能进行语音合成

4. **异步任务处理**
   - IMS 和 EMO 视频生成都是异步任务，需要轮询查询结果
   - CosyVoice 音色创建也是异步，需要等待状态变为 OK

5. **文件格式要求**
   - 音频: WAV (16bit), MP3 推荐
   - 图片: JPG, PNG 推荐
   - 视频: MP4 (H.264 编码)

### 4.4 错误处理

常见错误码及处理：

| 服务 | 错误码 | 说明 | 解决方案 |
|------|--------|------|----------|
| 通用 | InvalidApiKey | API Key无效 | 检查环境变量配置 |
| IMS | Throttling.User | 超出QPS限制 | 降低请求频率或联系客服提升配额 |
| CosyVoice | InvalidAudio | 音频不符合要求 | 检查音频时长、格式、质量 |
| EMO | ImageCheckFailed | 图像检测未通过 | 更换图片或调整图片质量 |

### 4.5 完整业务流程代码框架

```python
class StoryVideoProcessor:
    def __init__(self):
        self.ims_client = self._init_ims_client()
        self.voice_service = VoiceEnrollmentService()

    def process_story_video(self, original_video_path, parent_audio_path, parent_photo_path):
        """
        处理儿童故事视频，添加父母声音和数字人
        """
        # 步骤1: 上传文件到OSS
        video_url = self.upload_to_oss(original_video_path, "videos/original.mp4")
        audio_sample_url = self.upload_to_oss(parent_audio_path, "audio/parent_sample.wav")
        photo_url = self.upload_to_oss(parent_photo_path, "images/parent_photo.jpg")

        # 步骤2: IMS提取字幕
        subtitles = self.extract_subtitles(video_url)

        # 步骤3: CosyVoice声音克隆
        voice_id = self.clone_voice(audio_sample_url)
        parent_voice_audio = self.synthesize_speech(voice_id, subtitles)
        parent_voice_url = self.upload_to_oss(parent_voice_audio, "audio/parent_voice.mp3")

        # 步骤4: EMO生成数字人视频
        digital_avatar_url = self.generate_digital_avatar(photo_url, parent_voice_url)

        # 步骤5: IMS视频合成
        final_video_url = self.compose_final_video(
            video_url,           # 原视频（静音）
            parent_voice_url,    # 父母声音
            digital_avatar_url   # 数字人头像
        )

        return final_video_url

    def extract_subtitles(self, video_url):
        """IMS提取字幕"""
        # 调用 SubmitMediaProducingJob 配置字幕提取
        pass

    def clone_voice(self, audio_url):
        """CosyVoice克隆声音"""
        voice_id = self.voice_service.create_voice(
            target_model='cosyvoice-v3-plus',
            prefix='parentvoice',
            url=audio_url
        )
        # 等待音色就绪
        return voice_id

    def synthesize_speech(self, voice_id, text):
        """语音合成"""
        synthesizer = SpeechSynthesizer(
            model='cosyvoice-v3-plus',
            voice=voice_id
        )
        return synthesizer.call(text)

    def generate_digital_avatar(self, photo_url, audio_url):
        """EMO生成数字人"""
        # 1. 图像检测
        face_bbox, ext_bbox = self.detect_face(photo_url)
        # 2. 创建视频任务
        task_id = self.create_emo_task(photo_url, audio_url, face_bbox, ext_bbox)
        # 3. 等待任务完成
        return self.wait_for_task(task_id)

    def compose_final_video(self, video_url, audio_url, avatar_url):
        """IMS合成最终视频"""
        # 调用 SubmitMediaProducingJob 配置Timeline
        pass
```

---

## 五、参考资源

### 官方文档链接

1. **CosyVoice 声音克隆**
   - API 参考: https://help.aliyun.com/zh/model-studio/cosyvoice-clone-api
   - Python SDK: https://help.aliyun.com/zh/model-studio/cosyvoice-python-sdk

2. **悦动人像 EMO**
   - 快速入门: https://help.aliyun.com/zh/model-studio/emo-quick-start
   - 图像检测 API: https://help.aliyun.com/zh/model-studio/emo-detect-api
   - 视频生成 API: https://help.aliyun.com/zh/model-studio/emo-api

3. **智能媒体服务 IMS**
   - 产品概览: https://help.aliyun.com/zh/ims/
   - API 目录: https://help.aliyun.com/zh/ims/developer-reference/api-ice-2020-11-09-dir/
   - Timeline 配置: https://help.aliyun.com/zh/ims/developer-reference/timeline-configuration-description

### SDK 安装

```bash
# CosyVoice + EMO (DashScope SDK)
pip install dashscope

# 智能媒体服务 IMS
pip install aliyun-python-sdk-ice

# 阿里云OSS
pip install oss2
```

---

## 六、常见问题 FAQ

### Q1: 能否只克隆旁白（讲故事的），保留其他人物对话？
**A**: 目前阿里云 CosyVoice 尚未支持多说话人分离功能。如需实现，需要先用其他工具（如音轨分离工具）将旁白与对话分开，然后仅对旁白部分进行声音克隆和替换。

### Q2: 数字人头像的位置和大小如何控制？
**A**: 通过 IMS 的 Timeline 配置中的 EffectTracks 参数控制：
```json
{
  "EffectTracks": [{
    "EffectTrackClips": [{
      "X": 1520,      // 距离左边距离（px）
      "Y": 100,       // 距离上边距离（px）
      "Width": 300,   // 宽度（px）
      "Height": 300   // 高度（px）
    }]
  }]
}
```

### Q3: 如何提高声音克隆的相似度？
**A**:
1. 提供高质量音频样本（无背景噪音、清晰人声）
2. 音频时长保持在 15-20 秒最佳
3. 使用 cosyvoice-v3-plus 模型（效果最佳）
4. 确保样本音频的语速、语调接近目标风格

### Q4: 视频合成失败怎么办？
**A**: 常见原因及解决方案：
1. OSS URL 无法访问 → 检查 Bucket 权限设置为公共读
2. Timeline 配置错误 → 参考官方文档示例
3. 素材格式不支持 → 转换为 MP4 (H.264) 或 MP3
4. 超出资源限制 → 检查视频分辨率、素材总大小

---

**文档版本**: v1.0
**最后更新**: 2025-12-26
**维护者**: Echobot 开发团队
